{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7a8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be53914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.text if response.ok else None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae81abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links():\n",
    "    \n",
    "    all_links = []\n",
    "    domain = 'https://tyv.wikipedia.org'\n",
    "    \n",
    "    with open('./cat_tyv_links_wiki.txt', 'r') as f:\n",
    "        cat_links = f.read()\n",
    "    \n",
    "    cat_links = cat_links.split()\n",
    "    \n",
    "    for link in tqdm(cat_links):\n",
    "        html = get_html_page(link)\n",
    "        if not html: continue\n",
    "            \n",
    "        soup = BeautifulSoup(html)\n",
    "        tags_a = soup.find('div', {'class': 'mw-category-generated'}).find_all('a')\n",
    "        for tag_a in tags_a:\n",
    "            post_link = tag_a['href']\n",
    "            full_link = domain + post_link\n",
    "            all_links.append(full_link)\n",
    "            \n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a523e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = get_all_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246c2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesCollection():\n",
    "    def __init__(self, page_links=[], filename='./all_links.txt'):\n",
    "        self.page_links = []\n",
    "        self.filename = filename\n",
    "        self.dirty_corpus = []\n",
    "    \n",
    "    def get_html_page(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            return response.text if response.ok else None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def make_list_from_file(self):\n",
    "        with open(self.filename, mode='r') as f:\n",
    "            self.page_links = f.read()\n",
    "            \n",
    "        self.page_links = self.page_links.split()\n",
    "    \n",
    "    def make_raw_corpus(self, num_links=None):\n",
    "        links_processed = self.page_links[:num_links] if num_links else self.page_links\n",
    "        for link in tqdm(links_processed):\n",
    "            html = self.get_html_page(link)\n",
    "\n",
    "            if not html: continue\n",
    "            soup = BeautifulSoup(html)\n",
    "            \n",
    "            title = soup.find('h1', {'id': 'firstHeading'}).text\n",
    "            tags = soup.find('div', {'id': 'bodyContent', 'class': 'vector-body'}).find_all('p')\n",
    "            \n",
    "            text = [tag.text for tag in tags]\n",
    "            text = ' '.join(text)\n",
    "            text = '<>'.join((title, text))\n",
    "            text = '<>'.join((link, text))\n",
    "\n",
    "            self.dirty_corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877a9544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02643871307373047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5337,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c07a2beccb044c29245da8b92edbfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PagesCollector = ArticlesCollection()\n",
    "\n",
    "PagesCollector.make_list_from_file()\n",
    "PagesCollector.make_raw_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tyv_token(token):\n",
    "    \n",
    "    for ch in token:\n",
    "        if ch not in tyv_alphabet: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "857e797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    tyv_alphabet = 'АБВГДЕЁЖЗИЙКЛМНҢОӨПРСТУҮФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнңоөпрстуүфхцчшщъыьэюя'\n",
    "    res_str = ''\n",
    "    \n",
    "    one_space_regex = r\"\\s((\\s)(\\s+)?)?\"\n",
    "    \n",
    "    for ch in text:\n",
    "        if ch not in tyv_alphabet:\n",
    "            res_str += ' '\n",
    "        else:\n",
    "            res_str += ch\n",
    "            \n",
    "    \n",
    "    res_str = res_str.lower()\n",
    "    \n",
    "    try:\n",
    "        res_str = re.sub(one_space_regex, ' ', res_str)    \n",
    "        res_str = res_str if res_str[0] != ' ' else res_str[1:]\n",
    "        res_str = res_str if res_str[-1] != ' ' else res_str[:-1]\n",
    "        \n",
    "    except IndexError as e:\n",
    "            pass\n",
    "    \n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d013c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./clean_texts.txt', 'w') as f:\n",
    "\n",
    "    for raw_text in PagesCollector.dirty_corpus:\n",
    "\n",
    "        _, title, text = raw_text.split('<>')\n",
    "        title = clean_text(title)\n",
    "        text = clean_text(text)\n",
    "        \n",
    "        f.write(','.join((title, text)))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95bd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e1191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
